{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52824b89-532a-4e54-87e9-1410813cd39e",
   "metadata": {},
   "source": [
    "# Lab | Chains in LangChain\n",
    "\n",
    "## Outline\n",
    "\n",
    "* LLMChain\n",
    "* Sequential Chains\n",
    "  * SimpleSequentialChain\n",
    "  * SequentialChain\n",
    "* Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "id": "541eb2f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T13:01:49.947814Z",
     "start_time": "2024-10-21T13:01:49.923015Z"
    }
   },
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-10-21T13:03:04.749117Z",
     "start_time": "2024-10-21T13:03:04.714614Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b84e441b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "id": "974acf8e-8f88-42de-88f8-40a82cb58e8b",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-10-21T13:03:18.105222Z",
     "start_time": "2024-10-21T13:03:18.084867Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/Data.csv')"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "b7a09c35",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-10-21T13:03:20.369983Z",
     "start_time": "2024-10-21T13:03:20.343444Z"
    }
   },
   "source": [
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                   Product                                             Review\n",
       "0     Queen Size Sheet Set  I ordered a king size set. My only criticism w...\n",
       "1   Waterproof Phone Pouch  I loved the waterproof sac, although the openi...\n",
       "2      Luxury Air Mattress  This mattress had a small hole in the top of i...\n",
       "3           Pillows Insert  This is the best throw pillow fillers on Amazo...\n",
       "4  Milk Frother Handheld\\n   I loved this product. But they only seem to l..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Queen Size Sheet Set</td>\n",
       "      <td>I ordered a king size set. My only criticism w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Waterproof Phone Pouch</td>\n",
       "      <td>I loved the waterproof sac, although the openi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Luxury Air Mattress</td>\n",
       "      <td>This mattress had a small hole in the top of i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pillows Insert</td>\n",
       "      <td>This is the best throw pillow fillers on Amazo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Milk Frother Handheld\\n</td>\n",
       "      <td>I loved this product. But they only seem to l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "b940ce7c",
   "metadata": {},
   "source": [
    "## LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "id": "e92dff22",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-10-21T13:07:51.014467Z",
     "start_time": "2024-10-21T13:07:50.990423Z"
    }
   },
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "943237a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T13:03:40.023392Z",
     "start_time": "2024-10-21T13:03:39.964436Z"
    }
   },
   "source": [
    "#Replace None by your own value and justify\n",
    "llm = ChatOpenAI(temperature=0.7)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "cdcdb42d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T13:06:45.870598Z",
     "start_time": "2024-10-21T13:06:45.863998Z"
    }
   },
   "source": [
    "prompt = ChatPromptTemplate.from_template( \n",
    "  \"Describe following product: {product}:\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "d7abc20b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T13:05:22.568148Z",
     "start_time": "2024-10-21T13:05:22.548689Z"
    }
   },
   "source": "chain = LLMChain(llm=llm, prompt=prompt)",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hibi9\\AppData\\Local\\Temp\\ipykernel_28156\\1929250370.py:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=llm, prompt=prompt)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "ad44d1fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T13:05:50.666837Z",
     "start_time": "2024-10-21T13:05:49.065916Z"
    }
   },
   "source": [
    "product = \"Pillows Insert\"\n",
    "chain.run(product)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hibi9\\AppData\\Local\\Temp\\ipykernel_28156\\179363538.py:2: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chain.run(product)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A pillow insert is a cushioned inner piece that is placed inside a pillow cover to provide structure and support to the pillow. It is typically filled with materials such as polyester fiberfill, down feathers, or memory foam to provide comfort and shape to the pillow. Pillow inserts come in various sizes and shapes to fit different pillow covers and are often used to refresh or customize the look of a pillow.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "69b03469",
   "metadata": {},
   "source": [
    "## SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febee243",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "id": "2f31aa8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T13:07:23.964820Z",
     "start_time": "2024-10-21T13:07:23.907343Z"
    }
   },
   "source": [
    "llm = ChatOpenAI(temperature=0.9)\n",
    "\n",
    "# prompt template 1\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Describe following product: {product}:\"\n",
    ")\n",
    "\n",
    "# Chain 1\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "3f5d5b76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T13:10:13.202649Z",
     "start_time": "2024-10-21T13:10:13.193673Z"
    }
   },
   "source": [
    "\n",
    "# prompt template 2\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Please give a better product as {product}\"\n",
    ")\n",
    "# chain 2\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "6c1eb2c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T13:10:14.251029Z",
     "start_time": "2024-10-21T13:10:14.239929Z"
    }
   },
   "source": [
    "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],\n",
    "                                             verbose=True\n",
    "                                            )"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "78458efe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T13:10:18.324323Z",
     "start_time": "2024-10-21T13:10:15.511132Z"
    }
   },
   "source": [
    "overall_simple_chain.run(product)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new SimpleSequentialChain chain...\u001B[0m\n",
      "\u001B[36;1m\u001B[1;3mPillow insert is a rectangular or square-shaped filling that goes inside a pillow cover to provide support and comfort when used as a cushion for resting or sleeping. It is typically made of materials such as polyester, down feathers, or memory foam, and comes in various sizes to fit different pillow covers. The insert can be removed and replaced as needed to maintain the shape and firmness of the pillow.\u001B[0m\n",
      "\u001B[33;1m\u001B[1;3mA better product could be a customizable pillow insert that allows users to adjust the firmness and support level to their liking. This could be achieved through different compartments filled with materials of varying densities, allowing for a personalized sleeping experience. Additionally, the insert could have a breathable and hypoallergenic cover to ensure comfort and hygiene. This innovative design would provide a superior level of customization and comfort compared to traditional pillow inserts.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A better product could be a customizable pillow insert that allows users to adjust the firmness and support level to their liking. This could be achieved through different compartments filled with materials of varying densities, allowing for a personalized sleeping experience. Additionally, the insert could have a breathable and hypoallergenic cover to ensure comfort and hygiene. This innovative design would provide a superior level of customization and comfort compared to traditional pillow inserts.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "id": "0dd59bda-9d02-44e7-b3d6-2bec61b99d8f",
   "metadata": {},
   "source": [
    "**Repeat the above twice for different products**"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T13:11:02.091744Z",
     "start_time": "2024-10-21T13:10:58.372915Z"
    }
   },
   "cell_type": "code",
   "source": "overall_simple_chain.run(\"Luxury Air Mattress\")",
   "id": "f46403b36bf90a25",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new SimpleSequentialChain chain...\u001B[0m\n",
      "\u001B[36;1m\u001B[1;3mThe luxury air mattress is a high-end, premium quality bedding product designed for superior comfort and support. It is made with top-of-the-line materials that provide a plush and cushioned sleeping surface. The mattress is equipped with advanced air technology that allows users to adjust the firmness levels to their desired comfort level. It also features a built-in pump for easy inflation and deflation, as well as a durable construction that ensures long-lasting performance. The luxury air mattress is perfect for those seeking a luxurious sleeping experience while camping, traveling, or as an extra bed for guests.\u001B[0m\n",
      "\u001B[33;1m\u001B[1;3mThe DreamCloud Luxury Hybrid Mattress is a top-of-the-line bedding product that provides unparalleled comfort and support. Made with premium materials including gel-infused memory foam and individually wrapped coils, this mattress offers a plush and cushioned sleeping surface that contours to your body for ultimate comfort.\n",
      "\n",
      "The DreamCloud Luxury Hybrid Mattress features advanced technology that allows you to customize the firmness levels to your liking, ensuring a perfect night's sleep every time. With a built-in pump for easy inflation and deflation, this mattress is not only luxurious but also convenient.\n",
      "\n",
      "Constructed with durability in mind, the DreamCloud Luxury Hybrid Mattress is built to last, providing long-lasting performance for years to come. Whether you're camping, traveling, or hosting guests, this mattress is the perfect choice for those seeking a luxurious sleeping experience.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The DreamCloud Luxury Hybrid Mattress is a top-of-the-line bedding product that provides unparalleled comfort and support. Made with premium materials including gel-infused memory foam and individually wrapped coils, this mattress offers a plush and cushioned sleeping surface that contours to your body for ultimate comfort.\\n\\nThe DreamCloud Luxury Hybrid Mattress features advanced technology that allows you to customize the firmness levels to your liking, ensuring a perfect night's sleep every time. With a built-in pump for easy inflation and deflation, this mattress is not only luxurious but also convenient.\\n\\nConstructed with durability in mind, the DreamCloud Luxury Hybrid Mattress is built to last, providing long-lasting performance for years to come. Whether you're camping, traveling, or hosting guests, this mattress is the perfect choice for those seeking a luxurious sleeping experience.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T13:11:59.129563Z",
     "start_time": "2024-10-21T13:11:54.997435Z"
    }
   },
   "cell_type": "code",
   "source": "overall_simple_chain.run(\"Butterbrezel\")",
   "id": "34617a05311cd9d6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new SimpleSequentialChain chain...\u001B[0m\n",
      "\u001B[36;1m\u001B[1;3mButterbrezel is a traditional German snack made of a soft pretzel that is coated with a generous amount of butter. The pretzel is typically warm and chewy, with a crispy exterior and a soft, fluffy interior. The butter adds a rich and savory flavor to the pretzel, making it a delicious and indulgent treat. Butterbrezel is often enjoyed as a snack or as a light meal on the go.\u001B[0m\n",
      "\u001B[33;1m\u001B[1;3mOne delicious alternative to Butterbrezel is a gourmet filled pretzel. Imagine a soft, freshly baked pretzel filled with gooey mozzarella cheese, savory pepperoni, and zesty marinara sauce for a mouthwatering twist on a classic snack. This filled pretzel is baked to perfection, creating a crispy exterior and a warm, flavorful interior that will satisfy your cravings for something savory and satisfying. Perfect for enjoying on the go or as a satisfying snack at home, this gourmet filled pretzel is sure to become your new favorite indulgence.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'One delicious alternative to Butterbrezel is a gourmet filled pretzel. Imagine a soft, freshly baked pretzel filled with gooey mozzarella cheese, savory pepperoni, and zesty marinara sauce for a mouthwatering twist on a classic snack. This filled pretzel is baked to perfection, creating a crispy exterior and a warm, flavorful interior that will satisfy your cravings for something savory and satisfying. Perfect for enjoying on the go or as a satisfying snack at home, this gourmet filled pretzel is sure to become your new favorite indulgence.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "id": "7b5ce18c",
   "metadata": {},
   "source": [
    "## SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "id": "4c129ef6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T13:17:45.795398Z",
     "start_time": "2024-10-21T13:17:45.788804Z"
    }
   },
   "source": [
    "from langchain.chains import SequentialChain"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "id": "016187ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T13:32:31.512097Z",
     "start_time": "2024-10-21T13:32:31.437536Z"
    }
   },
   "source": [
    "llm = ChatOpenAI(temperature=0.9)\n",
    "\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "  \"Translate this review into german: {review}\"\n",
    ")\n",
    "\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, \n",
    "                     output_key='review1' #Give a name to your output\n",
    "                    )"
   ],
   "outputs": [],
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "id": "0fb0730e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T13:32:35.235063Z",
     "start_time": "2024-10-21T13:32:35.226698Z"
    }
   },
   "source": [
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Summarize this german review: {review1}\"\n",
    ")\n",
    "\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, \n",
    "                     output_key='review2' #give a name to this output\n",
    "                    )\n"
   ],
   "outputs": [],
   "execution_count": 72
  },
  {
   "cell_type": "code",
   "id": "6accf92d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T13:32:37.105756Z",
     "start_time": "2024-10-21T13:32:37.098023Z"
    }
   },
   "source": [
    "# prompt template 3: translate to english or other language\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Translate the summarized review '{review2}' into Japanese\"\n",
    ")\n",
    "# chain 3: input= Review and output= language\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt,\n",
    "                       output_key=\"review3\"\n",
    "                      )\n"
   ],
   "outputs": [],
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "id": "c7a46121",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T13:32:55.791244Z",
     "start_time": "2024-10-21T13:32:55.783516Z"
    }
   },
   "source": [
    "\n",
    "# prompt template 4: follow up message that take as inputs the two previous prompts' variables\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\n",
    "        \"Check if '{review3}' a Japanese translation of '{review2}'?'\"\n",
    ")\n",
    "chain_four = LLMChain(llm=llm, prompt=fourth_prompt,\n",
    "                      output_key=\"review4\"\n",
    "                     )\n"
   ],
   "outputs": [],
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "id": "89603117",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T13:32:57.701474Z",
     "start_time": "2024-10-21T13:32:57.692018Z"
    }
   },
   "source": [
    "# overall_chain: input= Review \n",
    "# and output= English_Review,summary, followup_message\n",
    "\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "    input_variables=['review'],\n",
    "    output_variables=['review1', 'review2', 'review3'],\n",
    "    verbose=True\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T13:33:26.825475Z",
     "start_time": "2024-10-21T13:33:26.808779Z"
    }
   },
   "cell_type": "code",
   "source": "df.Review[1]",
   "id": "4b9b79eddb017c0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I loved the waterproof sac, although the opening was made of a hard plastic. I don’t know if that would break easily. But I couldn’t turn my phone on, once it was in the pouch.'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "id": "51b04f45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T13:36:59.452319Z",
     "start_time": "2024-10-21T13:36:53.964566Z"
    }
   },
   "source": [
    "review = df.Review[1]\n",
    "overall_chain(review)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new SequentialChain chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'review': 'I loved the waterproof sac, although the opening was made of a hard plastic. I don’t know if that would break easily. But I couldn’t turn my phone on, once it was in the pouch.',\n",
       " 'review1': 'Ich mochte die wasserdichte Tasche, obwohl die Öffnung aus hartem Kunststoff gefertigt war. Ich weiß nicht, ob das leicht brechen würde. Aber ich konnte mein Telefon nicht einschalten, sobald es sich in der Hülle befand.',\n",
       " 'review2': 'The reviewer liked the waterproof bag, although they were concerned about the opening being made of hard plastic. They were unsure if it would easily break. Additionally, they had trouble turning on their phone while it was inside the case.',\n",
       " 'review3': 'レビュアーは防水バッグが好きだったが、開口部が硬いプラスチックで作られていることに懸念を抱いていた。すぐに壊れるかどうかわからなかった。さらに、ケースの中に入れたまま電話をオンにするのに苦労していた。'}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 80
  },
  {
   "cell_type": "markdown",
   "id": "3187cf07-458a-4226-bec7-3dec7ee47af2",
   "metadata": {},
   "source": [
    "**Repeat the above twice for different products or reviews**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3041ea4c",
   "metadata": {},
   "source": [
    "## Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "id": "ade83f4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T13:37:32.249677Z",
     "start_time": "2024-10-21T13:37:32.240269Z"
    }
   },
   "source": [
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise\\\n",
    "and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit\\\n",
    "that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. \\\n",
    "You are great at answering math questions. \\\n",
    "You are so good because you are able to break down \\\n",
    "hard problems into their component parts, \n",
    "answer the component parts, and then put them together\\\n",
    "to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "history_template = \"\"\"You are a very good historian. \\\n",
    "You have an excellent knowledge of and understanding of people,\\\n",
    "events and contexts from a range of historical periods. \\\n",
    "You have the ability to think, reflect, debate, discuss and \\\n",
    "evaluate the past. You have a respect for historical evidence\\\n",
    "and the ability to make use of it to support your explanations \\\n",
    "and judgements.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "computerscience_template = \"\"\" You are a successful computer scientist.\\\n",
    "You have a passion for creativity, collaboration,\\\n",
    "forward-thinking, confidence, strong problem-solving capabilities,\\\n",
    "understanding of theories and algorithms, and excellent communication \\\n",
    "skills. You are great at answering coding questions. \\\n",
    "You are so good because you know how to solve a problem by \\\n",
    "describing the solution in imperative steps \\\n",
    "that a machine can easily interpret and you know how to \\\n",
    "choose a solution that has a good balance between \\\n",
    "time complexity and space complexity. \n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\""
   ],
   "outputs": [],
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "id": "5f590e9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T13:38:30.625119Z",
     "start_time": "2024-10-21T13:38:30.608082Z"
    }
   },
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"physics\", \n",
    "        \"description\": \"Good for answering questions about physics\", \n",
    "        \"prompt_template\": physics_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\", \n",
    "        \"description\": \"Good for answering math questions\", \n",
    "        \"prompt_template\": math_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"History\", \n",
    "        \"description\": \"Good for answering history questions\", \n",
    "        \"prompt_template\": history_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"computer science\", \n",
    "        \"description\": \"Good for answering computer science questions\", \n",
    "        \"prompt_template\": computerscience_template\n",
    "    }\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 87
  },
  {
   "cell_type": "code",
   "id": "31b06fc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T13:38:16.290069Z",
     "start_time": "2024-10-21T13:38:15.928411Z"
    }
   },
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.prompts import PromptTemplate"
   ],
   "outputs": [],
   "execution_count": 83
  },
  {
   "cell_type": "code",
   "id": "f3f50bcc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T13:38:18.120187Z",
     "start_time": "2024-10-21T13:38:18.044547Z"
    }
   },
   "source": [
    "llm = ChatOpenAI(temperature=0)"
   ],
   "outputs": [],
   "execution_count": 84
  },
  {
   "cell_type": "code",
   "id": "8eefec24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T13:38:33.833722Z",
     "start_time": "2024-10-21T13:38:33.824335Z"
    }
   },
   "source": [
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain  \n",
    "    \n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)"
   ],
   "outputs": [],
   "execution_count": 88
  },
  {
   "cell_type": "code",
   "id": "9f98018a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T13:39:09.788076Z",
     "start_time": "2024-10-21T13:39:09.779856Z"
    }
   },
   "source": [
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)"
   ],
   "outputs": [],
   "execution_count": 89
  },
  {
   "cell_type": "code",
   "id": "11b2e2ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T13:39:26.863146Z",
     "start_time": "2024-10-21T13:39:26.855294Z"
    }
   },
   "source": [
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n",
    "language model select the model prompt best suited for the input. \\\n",
    "You will be given the names of the available prompts and a \\\n",
    "description of what the prompt is best suited for. \\\n",
    "You may also revise the original input if you think that revising\\\n",
    "it will ultimately lead to a better response from the language model.\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
    "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: \"destination\" MUST be one of the candidate prompt \\\n",
    "names specified below OR it can be \"DEFAULT\" if the input is not\\\n",
    "well suited for any of the candidate prompts.\n",
    "REMEMBER: \"next_inputs\" can just be the original input \\\n",
    "if you don't think any modifications are needed.\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>>\"\"\""
   ],
   "outputs": [],
   "execution_count": 90
  },
  {
   "cell_type": "code",
   "id": "1387109d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T13:39:35.571616Z",
     "start_time": "2024-10-21T13:39:35.565873Z"
    }
   },
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ],
   "outputs": [],
   "execution_count": 91
  },
  {
   "cell_type": "code",
   "id": "2fb7d560",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T13:39:39.604678Z",
     "start_time": "2024-10-21T13:39:39.587646Z"
    }
   },
   "source": [
    "chain = MultiPromptChain(router_chain=router_chain, \n",
    "                         destination_chains=destination_chains, \n",
    "                         default_chain=default_chain, verbose=True\n",
    "                        )"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hibi9\\AppData\\Local\\Temp\\ipykernel_28156\\2048584746.py:1: LangChainDeprecationWarning: Use RunnableLambda to select from multiple prompt templates. See example in API reference: https://api.python.langchain.com/en/latest/chains/langchain.chains.router.multi_prompt.MultiPromptChain.html\n",
      "  chain = MultiPromptChain(router_chain=router_chain,\n"
     ]
    }
   ],
   "execution_count": 92
  },
  {
   "cell_type": "code",
   "id": "d86b2131",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T13:39:45.502054Z",
     "start_time": "2024-10-21T13:39:43.357122Z"
    }
   },
   "source": [
    "chain.run(\"What is black body radiation?\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new MultiPromptChain chain...\u001B[0m\n",
      "physics: {'input': 'What is black body radiation?'}\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Black body radiation refers to the electromagnetic radiation emitted by a perfect black body, which is an idealized physical body that absorbs all incident electromagnetic radiation and emits radiation at all frequencies. The radiation emitted by a black body depends only on its temperature and follows a specific distribution known as Planck's law. This type of radiation is important in understanding concepts such as thermal radiation and the behavior of objects at different temperatures.\""
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 93
  },
  {
   "cell_type": "code",
   "id": "3b717379",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T13:39:56.252499Z",
     "start_time": "2024-10-21T13:39:54.971502Z"
    }
   },
   "source": [
    "chain.run(\"what is 2 + 2\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new MultiPromptChain chain...\u001B[0m\n",
      "math: {'input': 'what is 2 + 2'}\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The answer to 2 + 2 is 4.'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 94
  },
  {
   "cell_type": "code",
   "id": "29e5be01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T13:41:04.224626Z",
     "start_time": "2024-10-21T13:41:00.895889Z"
    }
   },
   "source": "chain.run(\"Why is the GPU better than the CPU to train models?\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new MultiPromptChain chain...\u001B[0m\n",
      "computer science: {'input': 'Why is the GPU better than the CPU to train models?'}\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The GPU is better than the CPU for training models because of its parallel processing capabilities. GPUs have thousands of cores that can handle multiple tasks simultaneously, making them much faster at performing matrix operations and other computations required for training machine learning models. This parallel processing power allows GPUs to significantly reduce the time it takes to train models compared to CPUs, which have fewer cores and are better suited for sequential processing tasks. Additionally, GPUs are optimized for handling large amounts of data and complex mathematical calculations, making them ideal for training deep learning models that require intensive computations. Overall, the GPU's ability to handle parallel processing makes it a more efficient and effective choice for training models compared to the CPU.\""
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 96
  },
  {
   "cell_type": "markdown",
   "id": "09e0c60b-7ae0-453e-9467-142d8dafee6e",
   "metadata": {},
   "source": [
    "**Repeat the above at least once for different inputs and chains executions - Be creative!**"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T14:00:25.653893Z",
     "start_time": "2024-10-21T14:00:25.638401Z"
    }
   },
   "cell_type": "code",
   "source": [
    "florist_template = \"\"\" You have an incredible eye for design. You're a master \\\n",
    "at arranging flowers, creating stunning bouquets and arrangements that \\\n",
    "convey the perfect emotion. You achieve this by skillfully considering \\\n",
    "the individual characteristics of each flower – its color, shape, and \\\n",
    "texture – and then artfully combining them to create a harmonious and expressive whole.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "marketing_template = \"\"\" You as a Marketing Guru have a talent for connecting with people. \\\n",
    "You're a skilled communicator, able to identify and understand the \\\n",
    "needs of your audience. You excel at crafting compelling messages \\\n",
    "that resonate with potential customers, by carefully analyzing their \\\n",
    "interests and motivations, and then tailoring your approach to effectively reach them.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "developer_template = \"\"\" You are one of the best developers of the world. \\\n",
    "You have an excellent knowledge of and understanding of code \\\n",
    "in mostly all languages. \\\n",
    "You have the ability to think, reflect, debate, discuss and \\\n",
    "evaluate why certain code is good or bad. Or what code is correct to solve a problem.\\\n",
    "You mostly use ruby to explain things, as it's the best development language in your opinion\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "astronaut_template = \"\"\" You possess extraordinary courage and a thirst for exploration. \\\n",
    "You're a skilled astronaut, capable of operating complex spacecraft and conducting crucial \\\n",
    "research in the challenging environment of space. You achieve this by meticulously mastering \\\n",
    "intricate technical skills, maintaining unwavering focus in demanding situations, and \\\n",
    "collaborating effectively with your crewmates to accomplish ambitious missions beyond Earth.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\""
   ],
   "id": "4c77da82ed4ab53b",
   "outputs": [],
   "execution_count": 117
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T13:59:22.946316Z",
     "start_time": "2024-10-21T13:59:22.935084Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"florist\", \n",
    "        \"description\": \"Good for answering questions about flowers\", \n",
    "        \"prompt_template\": florist_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"marketing\", \n",
    "        \"description\": \"Good for answering marketing questions\", \n",
    "        \"prompt_template\": marketing_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"developer\", \n",
    "        \"description\": \"Good for answering questions about development\", \n",
    "        \"prompt_template\": developer_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"astronaut\", \n",
    "        \"description\": \"Good for answering questions about the space and spaceships\", \n",
    "        \"prompt_template\": astronaut_template\n",
    "    }\n",
    "]"
   ],
   "id": "36fcad91d926fd1c",
   "outputs": [],
   "execution_count": 108
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T14:00:58.310667Z",
     "start_time": "2024-10-21T14:00:58.263191Z"
    }
   },
   "cell_type": "code",
   "source": "llm = ChatOpenAI(temperature=0)",
   "id": "7e18d557aacc0041",
   "outputs": [],
   "execution_count": 118
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T14:01:11.674404Z",
     "start_time": "2024-10-21T14:01:11.660154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain\n",
    "\n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)\n",
    "destinations_str"
   ],
   "id": "3c2d5c52254ef6eb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'florist: Good for answering questions about flowers\\nmarketing: Good for answering marketing questions\\ndeveloper: Good for answering questions about development\\nastronaut: Good for answering questions about the space and spaceships'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T14:01:21.212271Z",
     "start_time": "2024-10-21T14:01:21.205730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)"
   ],
   "id": "aa0123ae8350a4e1",
   "outputs": [],
   "execution_count": 121
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T14:01:34.537194Z",
     "start_time": "2024-10-21T14:01:34.520921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ],
   "id": "ca37f1929c8fe347",
   "outputs": [],
   "execution_count": 123
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T14:01:36.245973Z",
     "start_time": "2024-10-21T14:01:36.234974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chain = MultiPromptChain(router_chain=router_chain, \n",
    "                         destination_chains=destination_chains, \n",
    "                         default_chain=default_chain, verbose=True\n",
    "                        )"
   ],
   "id": "1c5c6579214314aa",
   "outputs": [],
   "execution_count": 124
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T14:01:39.839544Z",
     "start_time": "2024-10-21T14:01:37.650463Z"
    }
   },
   "cell_type": "code",
   "source": "chain.run(\"what greenery can be used to create a boucet\")",
   "id": "fcdd6321945f157a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new MultiPromptChain chain...\u001B[0m\n",
      "florist: {'input': 'what greenery can be used to create a bouquet'}\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'There are many types of greenery that can be used to create a beautiful bouquet. Some popular options include eucalyptus, ferns, ivy, salal, and ruscus. These greenery options can add texture, depth, and contrast to a bouquet, enhancing the overall look and feel of the arrangement. Additionally, greenery can help to fill out a bouquet and provide a lush backdrop for the flowers. Experimenting with different types of greenery can help you create a unique and visually appealing bouquet.'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 125
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T14:01:49.697684Z",
     "start_time": "2024-10-21T14:01:42.490469Z"
    }
   },
   "cell_type": "code",
   "source": "chain.run(\"How to develop an API to Mailgun?\")",
   "id": "e3d3127c795ee907",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new MultiPromptChain chain...\u001B[0m\n",
      "developer: {'input': 'How to develop an API to Mailgun?'}\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"To develop an API to Mailgun using Ruby, you can follow these steps:\\n\\n1. First, you need to sign up for a Mailgun account and obtain your API key and domain name.\\n\\n2. Install the `mailgun-ruby` gem by adding it to your Gemfile and running `bundle install`.\\n\\n3. Create a new Ruby file (e.g. `mailgun_api.rb`) and require the `mailgun-ruby` gem at the top of the file.\\n\\n4. Initialize the Mailgun client with your API key and domain name:\\n\\n```ruby\\nrequire 'mailgun-ruby'\\n\\nmailgun = Mailgun::Client.new(api_key: 'YOUR_API_KEY', domain: 'YOUR_DOMAIN_NAME')\\n```\\n\\n5. Now you can start using the Mailgun API to send emails, manage mailing lists, and more. Here's an example of sending an email using the Mailgun API:\\n\\n```ruby\\nmailgun.messages.send_email(\\n  from: 'you@example.com',\\n  to: 'recipient@example.com',\\n  subject: 'Hello from Mailgun',\\n  text: 'This is a test email sent using the Mailgun API'\\n)\\n```\\n\\n6. You can also use the Mailgun API to track email deliveries, bounces, and spam complaints. Check the Mailgun documentation for more information on available endpoints and parameters.\\n\\nBy following these steps, you can easily develop an API to Mailgun using Ruby and start integrating Mailgun's powerful email services into your applications.\""
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 126
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T14:02:05.347064Z",
     "start_time": "2024-10-21T14:02:01.552835Z"
    }
   },
   "cell_type": "code",
   "source": "chain.run(\"Where to out a video to rich the audience of hotel owners?\")",
   "id": "583bb8832770b463",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new MultiPromptChain chain...\u001B[0m\n",
      "marketing: {'input': 'Where to put a video to reach the audience of hotel owners?'}\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"To reach the audience of hotel owners, you should consider placing the video on platforms that are commonly used by this demographic. Some effective options may include:\\n\\n1. LinkedIn: Many hotel owners are active on LinkedIn, as it is a professional networking platform. You can share the video on your company page or in relevant industry groups to reach this audience.\\n\\n2. Hotel industry websites and forums: Consider reaching out to popular hotel industry websites and forums to see if they would be willing to feature your video. This can help you reach a targeted audience of hotel owners who are actively engaged in the industry.\\n\\n3. Email marketing: If you have a database of hotel owners' email addresses, consider sending out a targeted email campaign that includes a link to the video. This can help you reach a specific audience and drive engagement with your content.\\n\\n4. Social media advertising: Utilize social media advertising platforms such as Facebook, Instagram, or Twitter to target hotel owners specifically. You can create targeted ads that will appear in the feeds of hotel owners, increasing the likelihood that they will see and engage with your video.\\n\\nBy strategically placing your video on platforms that are frequented by hotel owners, you can effectively reach this audience and communicate your message in a way that resonates with them.\""
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 127
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T14:02:41.959146Z",
     "start_time": "2024-10-21T14:02:38.070881Z"
    }
   },
   "cell_type": "code",
   "source": "chain.run(\"Why it takes so long to travel to mars?\")",
   "id": "d243421daf8e1a9a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new MultiPromptChain chain...\u001B[0m\n",
      "astronaut: {'input': 'Why does it take so long to travel to Mars?'}\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Traveling to Mars takes a long time primarily due to the vast distance between Earth and Mars. The average distance between the two planets is about 225 million kilometers, but this distance can vary depending on their positions in their respective orbits. \\n\\nAdditionally, the speed at which spacecraft can travel is limited by the amount of fuel they can carry and the technology available for propulsion. Current spacecraft technology, such as chemical propulsion systems, can only travel at a certain speed, which means it takes several months to reach Mars.\\n\\nFurthermore, the journey to Mars must be carefully planned to take advantage of the most efficient trajectory, known as a Hohmann transfer orbit, which minimizes the amount of fuel needed for the journey. This requires precise calculations and timing to ensure the spacecraft arrives at Mars when it is closest to Earth in its orbit.\\n\\nOverall, the combination of the vast distance between Earth and Mars, the limitations of current spacecraft technology, and the need for precise planning all contribute to the long duration of a journey to Mars.'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 128
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T14:03:24.468381Z",
     "start_time": "2024-10-21T14:03:22.029849Z"
    }
   },
   "cell_type": "code",
   "source": "chain.run(\"Why it seems that the moon is really huge sometimes?\")",
   "id": "7baaeb53a7cf2e07",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new MultiPromptChain chain...\u001B[0m\n",
      "astronaut: {'input': 'Why does the moon appear larger at certain times?'}\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The moon appears larger at certain times due to an optical illusion known as the \"moon illusion.\" This phenomenon occurs when the moon is near the horizon, where there are objects like trees, buildings, or mountains for reference. When the moon is closer to the horizon, our brain perceives it to be larger because it is being compared to familiar objects in the foreground. In reality, the size of the moon remains constant throughout its orbit around Earth.'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 129
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
