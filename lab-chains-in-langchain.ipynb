{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52824b89-532a-4e54-87e9-1410813cd39e",
   "metadata": {},
   "source": [
    "# Lab | Chains in LangChain\n",
    "\n",
    "## Outline\n",
    "\n",
    "* LLMChain\n",
    "* Sequential Chains\n",
    "  * SimpleSequentialChain\n",
    "  * SequentialChain\n",
    "* Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "541eb2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b84e441b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "974acf8e-8f88-42de-88f8-40a82cb58e8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./data/Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7a09c35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Queen Size Sheet Set</td>\n",
       "      <td>I ordered a king size set. My only criticism w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Waterproof Phone Pouch</td>\n",
       "      <td>I loved the waterproof sac, although the openi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Luxury Air Mattress</td>\n",
       "      <td>This mattress had a small hole in the top of i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pillows Insert</td>\n",
       "      <td>This is the best throw pillow fillers on Amazo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Milk Frother Handheld\\r\\n</td>\n",
       "      <td>I loved this product. But they only seem to l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Product  \\\n",
       "0       Queen Size Sheet Set   \n",
       "1     Waterproof Phone Pouch   \n",
       "2        Luxury Air Mattress   \n",
       "3             Pillows Insert   \n",
       "4  Milk Frother Handheld\\r\\n   \n",
       "\n",
       "                                              Review  \n",
       "0  I ordered a king size set. My only criticism w...  \n",
       "1  I loved the waterproof sac, although the openi...  \n",
       "2  This mattress had a small hole in the top of i...  \n",
       "3  This is the best throw pillow fillers on Amazo...  \n",
       "4  Â I loved this product. But they only seem to l...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b940ce7c",
   "metadata": {},
   "source": [
    "## LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e92dff22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from operator import itemgetter\n",
    "from typing import Literal\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "943237a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace None by your own value and justify\n",
    "llm = ChatOpenAI(temperature=0.6)\n",
    "\n",
    "# Justification: we want the model to be creative in writing descriptions, so the temperature should be higher - but we still want the description to make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdcdb42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template( \"Write a product description for {product} in 50 words or less\"\n",
    " \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d7abc20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old code\n",
    "#chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# New code:\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ad44d1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='One possible solution to creating a waterproof phone pouch is to use a combination of waterproof materials such as PVC or TPU, along with a secure sealing mechanism such as a ziplock or velcro closure. \\n\\nHere are the imperative steps to create a waterproof phone pouch:\\n\\n1. Choose a waterproof material such as PVC or TPU that is durable and flexible.\\n2. Cut the material to the desired size and shape to fit your phone.\\n3. Fold the material in half, with the waterproof side facing outwards.\\n4. Use a heat sealer or waterproof adhesive to seal the sides and bottom of the pouch, leaving the top open.\\n5. Add a secure closure mechanism such as a ziplock or velcro to ensure a tight seal.\\n6. Test the pouch by placing a paper towel inside and submerging it in water to check for any leaks.\\n7. Once the pouch is confirmed to be waterproof, insert your phone and seal it securely before using it near water.\\n\\nBy following these steps and choosing the right materials, you can create a waterproof phone pouch that will protect your phone from water damage while still allowing you to use it in various outdoor activities.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 234, 'prompt_tokens': 108, 'total_tokens': 342, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-feea18d9-3a0a-4a8d-8c6f-7f4ddd1ef611-0', usage_metadata={'input_tokens': 108, 'output_tokens': 234, 'total_tokens': 342, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product = \"Waterproof Phone Pouch\"\n",
    "# Old code\n",
    "#chain.run(product)\n",
    "\n",
    "# New code:\n",
    "chain.invoke(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b03469",
   "metadata": {},
   "source": [
    "## SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "febee243",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f31aa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.9)\n",
    "\n",
    "# prompt template 1\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a product description for {product} in 50 words or less\"\n",
    ")\n",
    "\n",
    "# Chain 1\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f5d5b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prompt template 2\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Summarize {first_prmpt} in the style of shakespeare\"\n",
    ")\n",
    "# chain 2\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c1eb2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],\n",
    "                                             verbose=True\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78458efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mKeep your phone safe and dry with our Waterproof Phone Pouch. Perfect for any outdoor activity, this pouch is 100% waterproof and allows you to use your touchscreen while keeping your phone protected. With an adjustable neck strap, you can take your phone wherever you go without worry.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mFear not the elements, for with our Waterproof Phone Pouch,\n",
      "Thy precious device shall be safe and dry, untouched by such touch.\n",
      "A marvel of technology, 100% waterproof it stands,\n",
      "Allowing thee to use thy touchscreen with nimble hands.\n",
      "\n",
      "With adjustable neck strap, thou can carry it with ease,\n",
      "Into the wild and untamed lands, wherever thou please.\n",
      "So fear not, dear traveller, take thy phone with thee,\n",
      "Protected and secure, as it should be.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Fear not the elements, for with our Waterproof Phone Pouch,\\nThy precious device shall be safe and dry, untouched by such touch.\\nA marvel of technology, 100% waterproof it stands,\\nAllowing thee to use thy touchscreen with nimble hands.\\n\\nWith adjustable neck strap, thou can carry it with ease,\\nInto the wild and untamed lands, wherever thou please.\\nSo fear not, dear traveller, take thy phone with thee,\\nProtected and secure, as it should be.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#overall_simple_chain.run(product)\n",
    "\n",
    "# New code:\n",
    "overall_simple_chain.invoke(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd59bda-9d02-44e7-b3d6-2bec61b99d8f",
   "metadata": {},
   "source": [
    "**Repeat the above twice for different products**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5ce18c",
   "metadata": {},
   "source": [
    "## SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c129ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "016187ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.9)\n",
    "\n",
    "\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "  \"Tell me which product the following review describes: {review}\"\n",
    ")\n",
    "\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, \n",
    "                     output_key= \"Review\" #Give a name to your output\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0fb0730e",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Summarize the {review} into 10 words or less\"\n",
    ")\n",
    "\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, \n",
    "                     output_key= \"Summary\" #give a name to this output\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6accf92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 3: translate to english or other language\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Translate the {Summary} into German\"\n",
    ")\n",
    "# chain 3: input= Review and output= language\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt,\n",
    "                       output_key= \"Translation\"\n",
    "                      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c7a46121",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prompt template 4: follow up message that take as inputs the two previous prompts' variables\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\n",
    "        \"Given the {Summary} and {Translation}, tell me which language the review was translated to\"\n",
    ")\n",
    "chain_four = LLMChain(llm=llm, prompt=fourth_prompt,\n",
    "                      output_key= \"Language\"\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "89603117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall_chain: input= Review \n",
    "# and output= English_Review,summary, followup_message\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "    input_variables= [\"review\"],\n",
    "    output_variables=[\"Summary\", \"Translation\", \"Language\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "51b04f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'review': \"Je trouve le goÃ»t mÃ©diocre. La mousse ne tient pas, c'est bizarre. J'achÃ¨te les mÃªmes dans le commerce et le goÃ»t est bien meilleur...\\r\\nVieux lot ou contrefaÃ§on !?\",\n",
       " 'Summary': 'GoÃ»t mÃ©diocre, mousse ne tient pas, possible contrefaÃ§on.',\n",
       " 'Translation': 'Der Geschmack ist mittelmÃ¤Ãig, der Schaum hÃ¤lt nicht, mÃ¶glicherweise eine FÃ¤lschung.',\n",
       " 'Language': 'The review was translated to French and German.'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = df.Review[5]\n",
    "#overall_chain(review)\n",
    "\n",
    "# New code:\n",
    "overall_chain.invoke(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3187cf07-458a-4226-bec7-3dec7ee47af2",
   "metadata": {},
   "source": [
    "**Repeat the above twice for different products or reviews**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3041ea4c",
   "metadata": {},
   "source": [
    "## Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ade83f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise\\\n",
    "and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit\\\n",
    "that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. \\\n",
    "You are great at answering math questions. \\\n",
    "You are so good because you are able to break down \\\n",
    "hard problems into their component parts, \n",
    "answer the component parts, and then put them together\\\n",
    "to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "history_template = \"\"\"You are a very good historian. \\\n",
    "You have an excellent knowledge of and understanding of people,\\\n",
    "events and contexts from a range of historical periods. \\\n",
    "You have the ability to think, reflect, debate, discuss and \\\n",
    "evaluate the past. You have a respect for historical evidence\\\n",
    "and the ability to make use of it to support your explanations \\\n",
    "and judgements.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "computerscience_template = \"\"\" You are a successful computer scientist.\\\n",
    "You have a passion for creativity, collaboration,\\\n",
    "forward-thinking, confidence, strong problem-solving capabilities,\\\n",
    "understanding of theories and algorithms, and excellent communication \\\n",
    "skills. You are great at answering coding questions. \\\n",
    "You are so good because you know how to solve a problem by \\\n",
    "describing the solution in imperative steps \\\n",
    "that a machine can easily interpret and you know how to \\\n",
    "choose a solution that has a good balance between \\\n",
    "time complexity and space complexity. \n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "default_template = \"\"\"You are a helpful assistant. \n",
    "Question: {input}\n",
    "Provide a clear, helpful answer.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5f590e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"physics\", \n",
    "        \"description\": \"Good for answering questions about physics\", \n",
    "        \"prompt_template\": physics_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\", \n",
    "        \"description\": \"Good for answering math questions\", \n",
    "        \"prompt_template\": math_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"history\", \n",
    "        \"description\": \"Good for answering history questions\", \n",
    "        \"prompt_template\": history_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"computer science\", \n",
    "        \"description\": \"Good for answering computer science questions\", \n",
    "        \"prompt_template\": computerscience_template\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"name\": \"DEFAULT\",\n",
    "        \"description\": \"Good for general questions\",\n",
    "        \"prompt_template\": default_template\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "31b06fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f3f50bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8eefec24",
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_chains = {}\n",
    "for info in prompt_infos:\n",
    "    prompt = ChatPromptTemplate.from_template(template=info[\"prompt_template\"])\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    expert_chains[info[\"name\"]] = chain  \n",
    "    \n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "11b2e2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n",
    "language model select the model prompt best suited for the input. \\\n",
    "You will be given the names of the available prompts and a \\\n",
    "description of what the prompt is best suited for. \\\n",
    "You may also revise the original input if you think that revising\\\n",
    "it will ultimately lead to a better response from the language model.\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
    "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: \"destination\" MUST be one of the candidate prompt \\\n",
    "names specified below OR it can be \"DEFAULT\" if the input is not\\\n",
    "well suited for any of the candidate prompts.\n",
    "REMEMBER: \"next_inputs\" can just be the original input \\\n",
    "if you don't think any modifications are needed.\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1387109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "\n",
    "router_prompt = ChatPromptTemplate.from_template(MULTI_PROMPT_ROUTER_TEMPLATE)\n",
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "\n",
    "class RouterOutput(TypedDict):\n",
    "    destination: Literal[\"pysics\", \"math\", \"history\", \"computer_science\", \"DEFAULT\"]\n",
    "\n",
    "router_chain = router_prompt | llm.with_structured_output(RouterOutput) | itemgetter(\"destination\")\n",
    "\n",
    "def route_to_chain (inputs: dict) -> str:\n",
    "    destination = inputs[\"destination\"]\n",
    "    query = inputs[\"query\"]\n",
    "    return expert_chains[destination].invoke({\"input\": query})\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"query\": RunnablePassthrough(),\n",
    "        \"destination\": lambda x:\n",
    "router_chain.invoke({\"destinations\": destinations_str,\n",
    "\"question\": x})\n",
    "    }\n",
    "    | RunnableLambda(route_to_chain)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2fb7d560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: What is black body radiation?\n",
      "Answer: Black body radiation refers to the electromagnetic radiation emitted by a perfect absorber and emitter of radiation, known as a black body. A black body absorbs all radiation that falls on it and emits radiation across a wide range of wavelengths. The spectrum of black body radiation is continuous and follows a specific distribution known as Planck's law. This phenomenon is important in understanding the behavior of objects at high temperatures, such as stars, and is also used in various fields of science and engineering.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Question: What is 2+2\n",
      "Answer: 2 + 2 equals 4.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Question: What caused World War I?\n",
      "Answer: World War I was caused by a combination of factors, including militarism, alliances, imperialism, and nationalism. The assassination of Archduke Franz Ferdinand of Austria-Hungary in 1914 was the immediate trigger that set off a chain of events leading to the war. However, underlying tensions and rivalries between European powers had been building for years, with each country seeking to expand its influence and territory. The complex system of alliances also played a significant role, as countries were obligated to come to the defense of their allies if they were attacked. Ultimately, a series of diplomatic failures and miscalculations led to the outbreak of war in 1914.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Question: Explain Big O notation\n",
      "Answer: Big O notation is a way to describe the efficiency of an algorithm in terms of how its running time or space requirements grow as the input size increases. It is used to analyze the worst-case scenario of an algorithm and provides an upper bound on its performance.\n",
      "\n",
      "In Big O notation, algorithms are classified based on how they scale with the size of the input. For example, an algorithm with a time complexity of O(n) means that its running time grows linearly with the size of the input. An algorithm with a time complexity of O(n^2) means that its running time grows quadratically with the size of the input.\n",
      "\n",
      "By using Big O notation, developers can compare different algorithms and choose the most efficient one for a given problem. It helps in understanding the scalability and efficiency of algorithms, making it an essential concept in computer science and software development.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Question: What is the forecast for today?\n",
      "Answer: The forecast for today is partly cloudy with a high of 75Â°F and a 20% chance of rain in the afternoon. Make sure to bring an umbrella just in case!\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Question: Explain what principle component analysis is using linear algebra\n",
      "Answer: Principal component analysis (PCA) is a technique used in statistics and data analysis to reduce the dimensionality of a dataset while preserving as much variance as possible. In linear algebra terms, PCA involves finding the eigenvectors and eigenvalues of the covariance matrix of the dataset.\n",
      "\n",
      "First, the covariance matrix of the dataset is calculated. This matrix represents the relationships between the different variables in the dataset. The eigenvectors and eigenvalues of this covariance matrix are then computed.\n",
      "\n",
      "The eigenvectors represent the directions in which the data varies the most, while the eigenvalues represent the amount of variance in the data along those directions. The eigenvectors with the highest eigenvalues are the principal components of the dataset.\n",
      "\n",
      "By projecting the data onto these principal components, PCA effectively reduces the dimensionality of the dataset while retaining as much of the original variance as possible. This can help in visualizing and understanding the underlying structure of the data, as well as in simplifying subsequent analysis.\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Test with different types of questions\n",
    "    questions = [\n",
    "        \"What is black body radiation?\", \n",
    "        \"What is 2+2\",      \n",
    "        \"What caused World War I?\",       \n",
    "        \"Explain Big O notation\",     \n",
    "        \"What is the forecast for today?\", \n",
    "        \"Explain what principle component analysis is using linear algebra\",\n",
    "       # \"What are cells?\" #still breaks it \n",
    "    ]\n",
    "    \n",
    "    for question in questions:\n",
    "        print(f\"\\nQuestion: {question}\")\n",
    "        result = chain.invoke(question)\n",
    "        print(f\"Answer: {result}\\n\")\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d86b2131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Black body radiation refers to the electromagnetic radiation emitted by a perfect absorber and emitter of radiation, known as a black body. A black body absorbs all radiation that falls on it and emits radiation across a wide range of wavelengths. The spectrum of black body radiation is continuous and follows a specific distribution known as Planck's law. This phenomenon is important in understanding the behavior of objects at high temperatures, such as stars, and is also used in various fields of science and engineering.\""
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What is black body radiation?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3b717379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2 + 2 equals 4.'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"what is 2 + 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "29e5be01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Every cell in our body contains DNA because DNA carries the genetic information that determines our unique characteristics and functions. This genetic information is essential for the growth, development, and functioning of our cells, tissues, and organs. DNA also plays a crucial role in passing on genetic traits from one generation to the next. Having DNA in every cell ensures that the genetic instructions are available for proper cell division, protein synthesis, and overall maintenance of our body.'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Why does every cell in our body contain DNA?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e0c60b-7ae0-453e-9467-142d8dafee6e",
   "metadata": {},
   "source": [
    "**Repeat the above at least once for different inputs and chains executions - Be creative!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
