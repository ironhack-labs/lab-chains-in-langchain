{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52824b89-532a-4e54-87e9-1410813cd39e",
   "metadata": {},
   "source": [
    "# Lab | Chains in LangChain\n",
    "\n",
    "## Outline\n",
    "\n",
    "* LLMChain\n",
    "* Sequential Chains\n",
    "  * SimpleSequentialChain\n",
    "  * SequentialChain\n",
    "* Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "541eb2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a61a7bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b84e441b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "974acf8e-8f88-42de-88f8-40a82cb58e8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r'C:\\Users\\Latif-Calderón\\OneDrive\\Documents\\ironhack 2024 2025\\lab-chains-in-langchain\\data\\Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7a09c35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Queen Size Sheet Set</td>\n",
       "      <td>I ordered a king size set. My only criticism w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Waterproof Phone Pouch</td>\n",
       "      <td>I loved the waterproof sac, although the openi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Luxury Air Mattress</td>\n",
       "      <td>This mattress had a small hole in the top of i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pillows Insert</td>\n",
       "      <td>This is the best throw pillow fillers on Amazo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Milk Frother Handheld\\r\\n</td>\n",
       "      <td>I loved this product. But they only seem to l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Product  \\\n",
       "0       Queen Size Sheet Set   \n",
       "1     Waterproof Phone Pouch   \n",
       "2        Luxury Air Mattress   \n",
       "3             Pillows Insert   \n",
       "4  Milk Frother Handheld\\r\\n   \n",
       "\n",
       "                                              Review  \n",
       "0  I ordered a king size set. My only criticism w...  \n",
       "1  I loved the waterproof sac, although the openi...  \n",
       "2  This mattress had a small hole in the top of i...  \n",
       "3  This is the best throw pillow fillers on Amazo...  \n",
       "4   I loved this product. But they only seem to l...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b940ce7c",
   "metadata": {},
   "source": [
    "## LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8758102f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_openai\n",
      "  Downloading langchain_openai-0.3.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting langchain-core<0.4.0,>=0.3.31 (from langchain_openai)\n",
      "  Downloading langchain_core-0.3.31-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.58.1 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from langchain_openai) (1.59.7)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
      "  Downloading tiktoken-0.8.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.31->langchain_openai) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.31->langchain_openai) (1.33)\n",
      "Collecting langsmith<0.4,>=0.1.125 (from langchain-core<0.4.0,>=0.3.31->langchain_openai)\n",
      "  Downloading langsmith-0.3.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.31->langchain_openai) (24.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.31->langchain_openai) (2.8.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.31->langchain_openai) (8.2.3)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.31->langchain_openai) (4.11.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (4.66.5)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain_openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain_openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain_openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.31->langchain_openai) (2.1)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.31->langchain_openai)\n",
      "  Downloading orjson-3.10.15-cp312-cp312-win_amd64.whl.metadata (42 kB)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.31->langchain_openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.31->langchain_openai) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.31->langchain_openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.31->langchain_openai) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.2.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.58.1->langchain_openai) (0.4.6)\n",
      "Downloading langchain_openai-0.3.2-py3-none-any.whl (54 kB)\n",
      "Downloading langchain_core-0.3.31-py3-none-any.whl (412 kB)\n",
      "Downloading tiktoken-0.8.0-cp312-cp312-win_amd64.whl (883 kB)\n",
      "   ---------------------------------------- 0.0/883.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 883.8/883.8 kB 3.6 MB/s eta 0:00:00\n",
      "Downloading langsmith-0.3.1-py3-none-any.whl (332 kB)\n",
      "Downloading orjson-3.10.15-cp312-cp312-win_amd64.whl (133 kB)\n",
      "Installing collected packages: orjson, tiktoken, langsmith, langchain-core, langchain_openai\n",
      "Successfully installed langchain-core-0.3.31 langchain_openai-0.3.2 langsmith-0.3.1 orjson-3.10.15 tiktoken-0.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3be4f80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.15-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from langchain) (2.0.34)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from langchain) (3.10.5)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.31 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from langchain) (0.3.31)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.3 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from langchain) (0.3.1)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.11.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.31->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.31->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.31->langchain) (4.11.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.31->langchain) (2.1)\n",
      "Downloading langchain-0.3.15-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ------------------------------- -------- 0.8/1.0 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 4.4 MB/s eta 0:00:00\n",
      "Downloading langchain_text_splitters-0.3.5-py3-none-any.whl (31 kB)\n",
      "Installing collected packages: langchain-text-splitters, langchain\n",
      "Successfully installed langchain-0.3.15 langchain-text-splitters-0.3.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e92dff22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f07e8de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Replace 'your-api-key' with your actual OpenAI API key\n",
    "llm = ChatOpenAI(api_key='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', temperature=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943237a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#original line didnt work so I replaced it with the one above\n",
    "#Replace None by your own value and justify\n",
    "###llm = ChatOpenAI(temperature=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef7d73b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your template\n",
    "template = \"Describe the product: {product_name}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cdcdb42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template( template)\n",
    " \n",
    "# Generate a response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7abc20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Latif-Calderón\\AppData\\Local\\Temp\\ipykernel_17080\\546483037.py:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=llm, prompt=prompt)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad44d1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Latif-Calderón\\AppData\\Local\\Temp\\ipykernel_17080\\27210130.py:2: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chain.run(product)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A waterproof phone pouch is a protective case designed to keep your phone safe from water damage. It is typically made of transparent plastic material that allows you to use your phone while it is sealed inside the pouch. The pouch is usually equipped with a secure closure mechanism, such as a ziplock or snap closure, to ensure that your phone stays dry even when submerged in water. Waterproof phone pouches are ideal for outdoor activities such as swimming, kayaking, and hiking, as well as for everyday use in rainy or wet conditions.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product = \"Waterproof phone pouch\"\n",
    "chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b03469",
   "metadata": {},
   "source": [
    "## SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "febee243",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f31aa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(api_key= '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', temperature=0.9)\n",
    "\n",
    "# prompt template 1\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "   template=\"Describe the product: {product_name}\"\n",
    ")\n",
    "\n",
    "# Chain 1\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f5d5b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prompt template 2\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "   template=\"Describe the product: {product_name}\"\n",
    ")\n",
    "# chain 2\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c1eb2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],\n",
    "                                             verbose=True\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "78458efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mThe waterproof phone pouch is a transparent and durable pouch that is designed to protect your phone from water damage. It has a secure snap-and-lock closure to ensure that your phone stays dry even when submerged in water. The pouch is lightweight and portable, making it easy to carry with you on adventures such as beach trips, hikes, or water sports. It also features a lanyard or strap that allows you to wear it around your neck or attach it to your bag for easy access. The pouch maintains touchscreen functionality so you can still use your phone while it is protected inside.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m\n",
      "\n",
      "Additionally, the pouch is compatible with most smartphones, including larger models, and can also accommodate other small personal items such as credit cards, keys, or cash. The transparent design allows you to easily see and access your phone without having to remove it from the pouch. Overall, the waterproof phone pouch is a versatile and practical accessory for anyone who wants to keep their phone safe and dry while enjoying outdoor activities.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nAdditionally, the pouch is compatible with most smartphones, including larger models, and can also accommodate other small personal items such as credit cards, keys, or cash. The transparent design allows you to easily see and access your phone without having to remove it from the pouch. Overall, the waterproof phone pouch is a versatile and practical accessory for anyone who wants to keep their phone safe and dry while enjoying outdoor activities.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_simple_chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd59bda-9d02-44e7-b3d6-2bec61b99d8f",
   "metadata": {},
   "source": [
    "**Repeat the above twice for different products**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3d3a8531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mEl hervidor de agua eléctrico es un electrodoméstico diseñado para calentar agua de forma rápida y segura. Consiste en una base que se conecta a la corriente eléctrica y un recipiente de acero inoxidable o vidrio que se coloca sobre esta base. Tiene un sistema de calentamiento interno que hierve el agua de manera eficiente y automática, y suele contar con un indicador luminoso que señala cuando el agua está lista. Es utilizado comúnmente para preparar infusiones, café, té, sopas instantáneas y otros alimentos que requieran agua caliente. Es una opción práctica y conveniente para tener en la cocina o en la oficina.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m1. Rápido calentamiento del agua: el hervidor de agua eléctrico calienta el agua de forma rápida y eficiente, permitiendo ahorrar tiempo en comparación con calentar agua en una olla tradicional.\n",
      "\n",
      "2. Seguridad: la mayoría de los hervidores de agua eléctricos cuentan con sistemas de seguridad que evitan que el aparato siga funcionando si se queda sin agua o si se sobrecalienta.\n",
      "\n",
      "3. Fácil de usar: simplemente se llena el recipiente con agua, se conecta a la corriente eléctrica y se enciende el aparato. Algunos modelos cuentan con botones de encendido y apagado, así como ajustes de temperatura.\n",
      "\n",
      "4. Indicador luminoso: muchos hervidores de agua eléctricos tienen un indicador luminoso que señala cuando el agua está lista, lo que facilita saber cuándo está listo para usar.\n",
      "\n",
      "5. Variedad de usos: aparte de calentar agua para infusiones, café o té, el hervidor de agua eléctrico también puede utilizarse para calentar agua para sopas instantáneas, noodles, tés instantáneos y otras recetas que requieran agua caliente.\n",
      "\n",
      "6. Diseño compacto: su diseño compacto y portátil hace que sea fácil de colocar en cualquier lugar de la cocina u oficina, sin ocupar demasiado espacio.\n",
      "\n",
      "7. Fácil limpieza: la mayoría de los hervidores de agua eléctricos cuentan con un recipiente desmontable que facilita la limpieza y mantenimiento del aparato.\n",
      "\n",
      "8. Eficiencia energética: al calentar solo la cantidad de agua que se necesita, el hervidor de agua eléctrico es más eficiente energéticamente que calentar una olla con agua en la estufa.\u001b[0m\n",
      "\u001b[38;5;200m\u001b[1;3mEl hervidor de agua eléctrico ofrece varios beneficios en comparación con calentar agua en una olla tradicional. En primer lugar, calienta el agua de forma rápida y eficiente, ahorrando tiempo. Además, la mayoría de los modelos cuentan con sistemas de seguridad para evitar accidentes. Su fácil uso y diseño compacto lo hacen conveniente para su uso en cualquier lugar. También ofrece variedad de usos, desde infusiones hasta sopas instantáneas. Su eficiencia energética lo hace una opción más sostenible en comparación con calentar agua en la estufa. En resumen, el hervidor de agua eléctrico se destaca por su rapidez, seguridad, conveniencia y eficiencia energética.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "El hervidor de agua eléctrico ofrece varios beneficios en comparación con calentar agua en una olla tradicional. En primer lugar, calienta el agua de forma rápida y eficiente, ahorrando tiempo. Además, la mayoría de los modelos cuentan con sistemas de seguridad para evitar accidentes. Su fácil uso y diseño compacto lo hacen conveniente para su uso en cualquier lugar. También ofrece variedad de usos, desde infusiones hasta sopas instantáneas. Su eficiencia energética lo hace una opción más sostenible en comparación con calentar agua en la estufa. En resumen, el hervidor de agua eléctrico se destaca por su rapidez, seguridad, conveniencia y eficiencia energética.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "\n",
    "# Initialize the ChatOpenAI with the API key and temperature\n",
    "llm = ChatOpenAI(api_key='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', temperature=0.9)\n",
    "\n",
    "# Define the first prompt template\n",
    "first_template = \"Describe the product: {input}\"\n",
    "first_prompt = ChatPromptTemplate.from_template(first_template)\n",
    "\n",
    "# Chain 1\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)\n",
    "\n",
    "# Define the second prompt template\n",
    "second_template = \"What are the key features of {input}?\"\n",
    "second_prompt = ChatPromptTemplate.from_template(second_template)\n",
    "\n",
    "# Chain 2\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)\n",
    "\n",
    "# Define the third prompt template\n",
    "third_template = \"Compare {input} with its competitors.\"\n",
    "third_prompt = ChatPromptTemplate.from_template(third_template)\n",
    "\n",
    "# Chain 3\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt)\n",
    "\n",
    "# Create the SimpleSequentialChain\n",
    "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two, chain_three], verbose=True)\n",
    "\n",
    "# Example usage\n",
    "inputs = {\"input\": \"Hervidor de agua eléctrico\"}\n",
    "result = overall_simple_chain.run(inputs)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5ce18c",
   "metadata": {},
   "source": [
    "## SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4c129ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "016187ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.9)\n",
    "\n",
    "\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "  #This prompt should translate a review\n",
    "  \"\"\"Je trouve le goût médiocre. La mousse ne tient pas, c'est bizarre. J'achète les mêmes dans le commerce et le goût est bien meilleur...\"\"\",\n",
    "  )\n",
    "\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, \n",
    "                     #output_key=None #Give a name to your output\n",
    "                     output_key=\"translation\" \n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0fb0730e",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Write a prompt to summarize a review\"\"\"\n",
    ")\n",
    "\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, \n",
    "                     output_key=\"Summary_of_the_review\"#gve a name to this output\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6accf92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 3: translate to english or other language\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Translate the review to English\"\"\"\n",
    ")\n",
    "# chain 3: input= Review and output= language\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt,\n",
    "                       output_key=\"Language\"\n",
    "                      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c7a46121",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prompt template 4: follow up message that take as inputs the two previous prompts' variables\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\n",
    "        \"\"\"Based on the translation \"{translation}\" and the key features \"{Summary_of_the_review}\", write a follow-up message.\"\"\"\n",
    ")\n",
    "chain_four = LLMChain(llm=llm, prompt=fourth_prompt,\n",
    "                      output_key=\"feature_follow_up\"\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "89603117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall_chain: input= Review \n",
    "# and output= English_Review,summary, followup_message\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "    input_variables=[\"Je trouve le goût médiocre. La mousse ne tient pas, c'est bizarre. J'achète les mêmes dans le commerce et le goût est bien meilleur...\"],\n",
    "    output_variables=[\"translation\", \"feature_follow_up\", \"Language\", \"Summary_of_the_review\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "51b04f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{\"Je trouve le goût médiocre. La mousse ne tient pas, c'est bizarre. J'achète les mêmes dans le commerce et le goût est bien meilleur...\": \"Je trouve le goût médiocre. La mousse ne tient pas, c'est bizarre. J'achète les mêmes dans le commerce et le goût est bien meilleur...\\r\\nVieux lot ou contrefaçon !?\",\n",
       " 'translation': \"Il est possible que la qualité des ingrédients utilisés dans la fabrication de cette mousse soit inférieure à celle des produits du commerce. Il est également possible que la mousse ait été mal préparée ou mal conservée, ce qui peut altérer son goût et sa texture. Il pourrait être intéressant d'essayer d'autres marques ou de faire votre propre mousse maison pour comparer les saveurs.\",\n",
       " 'feature_follow_up': 'Thank you for your feedback on the mousse product. It seems like there may be issues with the quality of ingredients or preparation that could be affecting the taste and texture. We suggest trying different brands or making your own homemade mousse to compare flavors. Your insights are valuable and will help others make informed choices.',\n",
       " 'Language': 'I recently stayed at this hotel and had a fantastic experience. The staff was very friendly and accommodating, the rooms were clean and comfortable, and the location was convenient. I would definitely recommend this hotel to anyone looking for a great place to stay.',\n",
       " 'Summary_of_the_review': '\"Summarize your experience with the product or service and provide your overall impression in a concise and informative manner.\"'}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = df.Review[5]\n",
    "overall_chain(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3187cf07-458a-4226-bec7-3dec7ee47af2",
   "metadata": {},
   "source": [
    "**Repeat the above twice for different products or reviews**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3041ea4c",
   "metadata": {},
   "source": [
    "## Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ade83f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise\\\n",
    "and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit\\\n",
    "that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. \\\n",
    "You are great at answering math questions. \\\n",
    "You are so good because you are able to break down \\\n",
    "hard problems into their component parts, \n",
    "answer the component parts, and then put them together\\\n",
    "to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "history_template = \"\"\"You are a very good historian. \\\n",
    "You have an excellent knowledge of and understanding of people,\\\n",
    "events and contexts from a range of historical periods. \\\n",
    "You have the ability to think, reflect, debate, discuss and \\\n",
    "evaluate the past. You have a respect for historical evidence\\\n",
    "and the ability to make use of it to support your explanations \\\n",
    "and judgements.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "computerscience_template = \"\"\" You are a successful computer scientist.\\\n",
    "You have a passion for creativity, collaboration,\\\n",
    "forward-thinking, confidence, strong problem-solving capabilities,\\\n",
    "understanding of theories and algorithms, and excellent communication \\\n",
    "skills. You are great at answering coding questions. \\\n",
    "You are so good because you know how to solve a problem by \\\n",
    "describing the solution in imperative steps \\\n",
    "that a machine can easily interpret and you know how to \\\n",
    "choose a solution that has a good balance between \\\n",
    "time complexity and space complexity. \n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "biology_template = \"\"\"You are a very good biologist. \\\n",
    "You have a deep understanding of the natural world. \\\n",
    "You are great at answering questions about biology. \\\n",
    "You are so good because you are able to break down \\\n",
    "complex biological systems into their component parts, \\\n",
    "answer the component parts, and then put them together \\\n",
    "to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5f590e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"physics\", \n",
    "        \"description\": \"Good for answering questions about physics\", \n",
    "        \"prompt_template\": physics_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\", \n",
    "        \"description\": \"Good for answering math questions\", \n",
    "        \"prompt_template\": math_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"History\", \n",
    "        \"description\": \"Good for answering history questions\", \n",
    "        \"prompt_template\": history_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"computer science\", \n",
    "        \"description\": \"Good for answering computer science questions\", \n",
    "        \"prompt_template\": computerscience_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"biology\", \n",
    "        \"description\": \"Good for answering biology questions\", \n",
    "        \"prompt_template\": biology_template\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "31b06fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f3f50bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8eefec24",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain  \n",
    "    \n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9f98018a",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "11b2e2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n",
    "language model select the model prompt best suited for the input. \\\n",
    "You will be given the names of the available prompts and a \\\n",
    "description of what the prompt is best suited for. \\\n",
    "You may also revise the original input if you think that revising\\\n",
    "it will ultimately lead to a better response from the language model.\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
    "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: \"destination\" MUST be one of the candidate prompt \\\n",
    "names specified below OR it can be \"DEFAULT\" if the input is not\\\n",
    "well suited for any of the candidate prompts.\n",
    "REMEMBER: \"next_inputs\" can just be the original input \\\n",
    "if you don't think any modifications are needed.\n",
    "\n",
    "Do NOT choose any prompt name that is not listed below. \\\n",
    "If the input does not fit any of the given prompts, choose \"DEFAULT\".\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1387109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2fb7d560",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = MultiPromptChain(router_chain=router_chain, \n",
    "                         destination_chains=destination_chains, \n",
    "                         default_chain=default_chain, verbose=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d86b2131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "physics: {'input': 'What is black body radiation?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Black body radiation refers to the electromagnetic radiation emitted by a perfect black body, which is an idealized physical body that absorbs all incident electromagnetic radiation and emits radiation at all frequencies. The radiation emitted by a black body depends only on its temperature and follows a specific distribution known as Planck's law. This type of radiation is important in understanding concepts such as thermal radiation and the behavior of objects at different temperatures.\""
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"What is black body radiation?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3b717379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "math: {'input': 'what is 2 + 2'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The answer to 2 + 2 is 4.'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"what is 2 + 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a6017ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "None: {'input': 'How does a route chain fit together?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A route chain is a series of interconnected routes that are used to guide a person or vehicle from one location to another. Each route in the chain is linked to the next one, creating a seamless path from the starting point to the destination.\\n\\nTo fit together, a route chain must be carefully planned and organized to ensure that each route flows smoothly into the next. This can involve selecting the most efficient and direct routes, considering factors such as traffic patterns, road conditions, and any potential obstacles or detours.\\n\\nAdditionally, each route in the chain must be clearly marked and easily identifiable to ensure that the person or vehicle following the chain can easily navigate from one point to the next. This may involve using signs, maps, GPS devices, or other navigation tools to help guide the way.\\n\\nOverall, a route chain fits together by creating a logical and efficient path that connects multiple routes in a seamless and cohesive manner, ultimately leading the traveler to their desired destination.'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"How does a route chain fit together?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "29e5be01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "biology: {'input': 'Why does every cell in our body contain DNA?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Every cell in our body contains DNA because DNA is the genetic material that carries the instructions for the development, functioning, and reproduction of all living organisms. DNA contains the information needed to build and maintain an organism, including the instructions for making proteins, which are essential for the structure and function of cells. Additionally, DNA is passed down from parent to offspring, allowing for the transmission of genetic information from one generation to the next. Having DNA in every cell ensures that each cell has the necessary information to carry out its specific functions and contribute to the overall functioning of the organism.'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"Why does every cell in our body contain DNA?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e0c60b-7ae0-453e-9467-142d8dafee6e",
   "metadata": {},
   "source": [
    "**Repeat the above at least once for different inputs and chains executions - Be creative!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3c06dedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "investment_template = \"\"\"You are a very good investment advisor. \\\n",
    "You have a deep understanding of the financial markets. \\\n",
    "You are great at answering questions about investments. \\\n",
    "You are so good because you are able to break down \\\n",
    "complex financial systems into their component parts, \\\n",
    "answer the component parts, and then put them together \\\n",
    "to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "electronics_engineering_template = \"\"\"You are a very good electronics engineer. \\\n",
    "You have a deep understanding of the electronics world. \\\n",
    "You are great at answering questions about electronics. \\\n",
    "You are so good because you are able to break down \\\n",
    "complex electronic systems into their component parts, \\\n",
    "answer the component parts, and then put them together \\\n",
    "to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "economic_template = \"\"\"You are a very good economist. \\\n",
    "You have a deep understanding of the economic world. \\\n",
    "You are great at answering questions about economics. \\\n",
    "You are so good because you are able to break down \\\n",
    "complex economic systems into their component parts, \\\n",
    "answer the component parts, and then put them together \\\n",
    "to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "spy_template = \"\"\"You are a very good spy. \\\n",
    "You have a deep understanding of the spy world. \\\n",
    "You are great at answering questions about spying. \\\n",
    "You are so good because you are able to break down \\\n",
    "complex spying systems into their component parts, \\\n",
    "answer the component parts, and then put them together \\\n",
    "to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8d120066",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"investment\", \n",
    "        \"description\": \"Good for answering questions about investments\", \n",
    "        \"prompt_template\": investment_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"electronics engineering\", \n",
    "        \"description\": \"Good for answering questions about electronics engineering\", \n",
    "        \"prompt_template\": electronics_engineering_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"economic\", \n",
    "        \"description\": \"Good for answering questions about economics\", \n",
    "        \"prompt_template\": economic_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"spy\", \n",
    "        \"description\": \"Good for answering questions about spying\", \n",
    "        \"prompt_template\": spy_template\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "dc37de65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.prompts import PromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "64cab129",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm= ChatOpenAI(temperature=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3c1eac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain\n",
    "\n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "de8b723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ef938ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n",
    "language model select the model prompt best suited for the input. \\\n",
    "You will be given the names of the available prompts and a \\\n",
    "description of what the prompt is best suited for. \\\n",
    "You may also revise the original input if you think that revising\\\n",
    "it will ultimately lead to a better response from the language model.\n",
    "\n",
    "<< FORMATTING >>\n",
    "return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
    "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: \"destination\" MUST be one of the candidate prompt \\\n",
    "names specified below OR it can be \"DEFAULT\" if the input is not\\\n",
    "well suited for any of the candidate prompts.\n",
    "REMEMBER: \"next_inputs\" can just be the original input \\\n",
    "if you don't think any modifications are needed.\n",
    "\n",
    "Do NOT choose any prompt name that is not listed below. \\\n",
    "If the input does not fit any of the given prompts, choose \"DEFAULT\".\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "\n",
    "{destinations}\n",
    "\n",
    "\n",
    "<< INPUT >>\n",
    "\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>>\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "07ef9ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a17ae828",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = MultiPromptChain(router_chain=router_chain,\n",
    "                            destination_chains=destination_chains, \n",
    "                            default_chain=default_chain, verbose=True\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ad2ad814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "investment: {'input': 'What is the best investment for a beginner?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"As a beginner, it is important to focus on building a solid foundation for your investment portfolio. One of the best investments for beginners is a low-cost index fund, such as an S&P 500 index fund. Index funds offer diversification by investing in a large number of companies within a specific market index, such as the S&P 500, which reduces individual stock risk. Additionally, index funds typically have lower fees compared to actively managed funds, making them a cost-effective option for beginners. \\n\\nIt is also important for beginners to consider their risk tolerance and investment goals before making any investment decisions. Consulting with a financial advisor can help you create a personalized investment plan that aligns with your objectives and time horizon. Remember, investing is a long-term commitment, so it's important to stay patient and disciplined with your investment strategy.\""
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"What is the best investment for a beginner?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2a6e536b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "electronics engineering: {'input': 'How to become a good electronics engineer?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Becoming a good electronics engineer requires a combination of education, experience, and continuous learning. Here are some steps you can take to become a successful electronics engineer:\\n\\n1. Get a solid education: Start by obtaining a bachelor's degree in electrical engineering or a related field. Make sure to focus on courses that cover topics such as circuit analysis, electronics, digital systems, and signal processing.\\n\\n2. Gain hands-on experience: Look for internships or co-op opportunities to gain practical experience working with electronic components and systems. Hands-on experience is crucial for understanding how theoretical concepts apply in real-world situations.\\n\\n3. Stay current with technology: The field of electronics is constantly evolving, so it's important to stay up-to-date with the latest advancements and trends. Attend conferences, workshops, and seminars to learn about new technologies and techniques.\\n\\n4. Develop problem-solving skills: Electronics engineering often involves solving complex problems and troubleshooting issues. Practice your problem-solving skills by working on projects and challenges that require critical thinking and analytical skills.\\n\\n5. Build a strong network: Connect with other professionals in the electronics engineering field through networking events, industry conferences, and online forums. Building a strong network can provide valuable opportunities for collaboration and learning.\\n\\n6. Continuously learn and improve: Electronics engineering is a dynamic field, so it's important to always be learning and improving your skills. Take online courses, read technical books, and seek out mentorship opportunities to expand your knowledge and expertise.\\n\\nBy following these steps and putting in the effort to continuously learn and grow, you can become a successful electronics engineer. Good luck on your journey!\""
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"How to become a good electronics engineer?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d0c67b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "economic: {'input': 'What is the economic impact of the pandemic?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The economic impact of the pandemic has been significant and far-reaching. The pandemic has led to widespread disruptions in global supply chains, reduced consumer demand, and increased unemployment rates. Many businesses have been forced to shut down or operate at reduced capacity, leading to economic losses and job losses.\\n\\nGovernments around the world have implemented various measures to mitigate the economic impact of the pandemic, including stimulus packages, grants, loans, and other forms of financial support. However, the long-term economic consequences of the pandemic are still uncertain and will likely depend on how quickly the global economy can recover from the effects of the pandemic.\\n\\nOverall, the pandemic has highlighted the fragility of the global economy and the importance of preparedness and resilience in the face of future crises. It has also underscored the need for collaboration and cooperation among nations to address global challenges and build a more sustainable and inclusive economy in the future.'"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run (\"What is the economic impact of the pandemic?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0d2dda1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "spy: {'input': 'How to become a good spy?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Becoming a good spy requires a combination of skills, training, and dedication. Here are some key steps to becoming a successful spy:\\n\\n1. Develop strong observational skills: Spies must be able to pay attention to detail and notice things that others might overlook.\\n\\n2. Master the art of communication: Spies need to be able to communicate effectively and discreetly with their contacts and fellow agents.\\n\\n3. Cultivate adaptability: Spies often find themselves in unpredictable situations and must be able to think on their feet and adapt to changing circumstances.\\n\\n4. Acquire technical skills: Knowledge of encryption, surveillance techniques, and other technical skills can be invaluable for a spy.\\n\\n5. Stay in top physical shape: Spies often find themselves in dangerous situations and need to be physically fit to handle the challenges they may face.\\n\\n6. Obtain proper training: Many intelligence agencies offer training programs for aspiring spies to develop their skills and knowledge in the field.\\n\\nOverall, becoming a good spy requires a combination of natural talent, acquired skills, and a commitment to the mission. It is a challenging but rewarding profession for those who are up to the task.'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"How to become a good spy?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4311904e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
